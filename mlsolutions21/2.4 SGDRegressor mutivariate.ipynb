{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-variate Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ML library uses the same SKLearn libraries under the hood. So the same approach that we used before to include multivariate and polynomial data also works in these libraries. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "Look at the multivariate example in Notebook 1.2. Now load data for the wine dataset, with sulphates and alcohol at explanatory variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "from ml import *\n",
    "data = wines('quality', 'sulphates', 'alcohol', scale=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center"
   },
   "source": [
    "# Model\n",
    "\n",
    "Use the SGDRegressor with a 'squared_loss' loss-function and a learning rate alpha of 0.01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SGDRegressor(eta0=0.01, learning_rate='invscaling', penalty = None, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the loss converges quite quickly to around 0.487. Notice that the loss is less than the loss when using only alcohol as an explanatory variable, therefore adding more information does seem to improve predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5930045595316757\n",
      "0.48705022533796855\n",
      "0.48704926848753605\n",
      "0.487048796053831\n",
      "0.4870484951882718\n",
      "0.48704827982447874\n",
      "0.48704811481779814\n",
      "0.48704798261948534\n",
      "0.4870478733007016\n",
      "0.487047780740092\n",
      "0.48704770091866\n"
     ]
    }
   ],
   "source": [
    "for _ in range(101):\n",
    "    model.partial_fit(data.train_X, data.train_y )\n",
    "    if _ % 10 == 0:\n",
    "        y_predict = model.predict(data.train_X)\n",
    "        print(mean_squared_error(y_predict, data.train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
