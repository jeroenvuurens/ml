{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text classification\n",
    "\n",
    "You assignment is to create a classifier for SMS-texts to detect which messages are spam and which are not. In the dataset, ham is used to identify messages that are not spam.\n",
    "\n",
    "To classify text, it is common to transform the text into vector representation. In a simple bag-of-word vector representation, every word in the collection is a feature and in each documents we simply count how often each word appears. So if our dictionary consists of [ i, am, hungy, and, thirsty ], then the text \"I am hungry\" would become (1, 1, 1, 0, 0), the text \"I am thirsty\" (1, 1, 0, 0, 1) and the text \"I am hungry and I am thirsty\" (2, 2, 1, 1, 1). Since these now are numbers, we can train a classifier like before.\n",
    "\n",
    "# Text parsing\n",
    "\n",
    "Several decisions affect the vectorization of text. Commonly, sentences are split on whitespace and punctuation marks to get words. Words are often lowercased and brought back to their stem (i.e. walk, walked, walking are all converted to their stem 'walk') and a list of relatively meaningless words, the so called 'stopwords', are removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/data/datasets/spam.csv\", encoding = 'latin-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check the Dataframe, for some reason during import 3 empty columns were created, remove them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### convert the Categories in column v1 to numbers. Since we want to detect spam, it makes sense to use 1 for spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['v1'] = df.v1.apply(lambda x: x == 'spam') * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(min_df=5, encoding='latin-1', stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = vectorizer.fit_transform(df.v2).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look at the shape, how many texts are there and how many words in the dictionary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 1602)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use n-fold cross validation to compute the recall. Take the average accuracy over the experiments. Depending on the number of splits you should see an accuracy around 87% for n=10. What does the recall stand for?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8724424466766699"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import recall_score, precision_score\n",
    "\n",
    "kf = KFold(n_splits=10, random_state=0)\n",
    "y = df.v1.to_numpy()\n",
    "recall = []\n",
    "for train, valid in kf.split(y):\n",
    "    train_X = features[train]\n",
    "    valid_X = features[valid]\n",
    "    train_y = y[train]\n",
    "    valid_y = y[valid]\n",
    "    \n",
    "    model = LogisticRegression(solver='liblinear', multi_class='auto')\n",
    "    model.fit(train_X, train_y)\n",
    "    pred_y = model.predict(valid_X)\n",
    "    recall.append(recall_score(valid_y, pred_y))\n",
    "sum(recall)/len(recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show the frequency of spam and ham."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4825\n",
       "1     747\n",
       "Name: v1, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.v1.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Since there is a big skew in the dataset, try to balance the training set and repeat the experiment. See what happens to the recall. You should see a big improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = np.where(y == 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = np.hstack([range(len(df)), pos, pos, pos, pos, pos, pos])\n",
    "X = features[ind]\n",
    "y = df.v1[ind].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9725281753273454"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf = KFold(n_splits=10, random_state=0)\n",
    "recall = []\n",
    "precision = []\n",
    "for train, valid in kf.split(y):\n",
    "    train_X = X[train]\n",
    "    valid_X = X[valid]\n",
    "    train_y = y[train]\n",
    "    valid_y = y[valid]\n",
    "    \n",
    "    model = LogisticRegression(solver='liblinear')\n",
    "    model.fit(train_X, train_y)\n",
    "    pred_y = model.predict(valid_X)\n",
    "    recall.append(recall_score(valid_y, pred_y))\n",
    "    precision.append(precision_score(valid_y, pred_y))\n",
    "\n",
    "sum(recall)/len(recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Also compute the precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(precision)/len(precision)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
