{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression with SKLearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SKLearn library also contains a LogisticRegression model. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "We load a classification version of the Wine dataset like before. Because we use SKLEarn we do not have to add a bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml import *\n",
    "data = wines_binary('quality', 'alcohol', 'pH', threshold = 6)\n",
    "data.plot2d()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model and Train\n",
    "\n",
    "Analogous to how we used LinearRegression, we import the LogisticRegression model of SKLearn, construct a model and fit it to the data.\n",
    "\n",
    "#### view the documentation for the fit method of the LogisticRegression model and fill in the ... to fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "??LogisticRegression.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit( ..., ... )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate\n",
    "\n",
    "The accuracy of the SKLearn model is very close to that of the mathematical derived version. Note that the coefficients between the model are not comparable, because in this case every multiple of the coefficients actually represents the same solution.\n",
    "\n",
    "SKLearn takes less time to learn the logistic regression model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(lr.intercept_, lr.coef_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy\n",
    "\n",
    "To compute the accuracy, we can sum up the cases where the true class in data.train_y is equal to the predicted class. For every training sample for which this equation is true, it will give a 1, otherwise zero. So the sum is the number of training examples that were correctly predicted. \n",
    "\n",
    "#### on the ... divide by the number of training samples, to get the fraction, better known as accuracy. You can use the len() function for the number of rows in a matrix or table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(data.train_y == lr.predict(data.train_X)) / ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
