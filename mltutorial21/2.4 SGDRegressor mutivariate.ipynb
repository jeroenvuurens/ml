{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-variate Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ML library uses the same SKLearn libraries under the hood. So the same approach that we used before to include multivariate and polynomial data also works in these libraries. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "Look at the multivariate example in Notebook 1.2. Now load data for the wine dataset, with sulphates and alcohol at explanatory variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "from ml import *\n",
    "data = wines('quality', 'sulphates', 'alcohol', scale=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center"
   },
   "source": [
    "# Model\n",
    "\n",
    "Use the SGDRegressor with a 'squared_loss' loss-function and a learning rate alpha of 0.01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SGDRegressor(eta0=0.01, learning_rate='invscaling', penalty = None, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding a good learning rate\n",
    "\n",
    "To find a proper learning rate $\\alpha$, try out a few values in the sequence 1e-5, 3e-5, 1e-4, 3e-4, 1e-3, etc. When the learning rate is set too high, the model does not converge. When the learning rate is set too low, it converges very slowly. Usually when you hit the sweet spot you will see that.\n",
    "\n",
    "We will transfer the learning loop into a function to try out.\n",
    "\n",
    "#### on the ... add the code to use the model to predict values for the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn(ùõº):\n",
    "    model = SGDRegressor(eta0=ùõº, learning_rate='invscaling', penalty = None)    \n",
    "    for _ in range(101):\n",
    "        model.partial_fit(data.train_X, data.train_y )\n",
    "        if _ % 10 == 0:\n",
    "            y_predict = ...\n",
    "            print(ùõº, mean_squared_error(y_predict, data.train_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try out the learn() function using a learning rate of 0.01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try a range of different values for the learning rate, what is the best learning rate to choose? What happens for ùõº=3?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ùõº in [1e-5, 3e-5, 1e-4, 3e-4, 1e-3, 3e-3, 1e-2, 3e-2, 1e-1, 3e-1, 1, 3]:\n",
    "    print('----')\n",
    "    learn(ùõº)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
