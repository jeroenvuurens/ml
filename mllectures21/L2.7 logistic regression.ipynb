{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "Logistic Regression is not a regression but a classification algorithm. It also happens to be one of the major stepping stones towards Neural Networks and therefore interesting to learn more about. This notebook demonstrates how Logistic Regression works.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "We can use a classifier on the Wine data set by converting the target variable to a boolean: $y = 1$ if the quality >= 6 or 0 otherwise. The easiest way is to create a new column for our label whether the wine is 'good'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ml import *\n",
    "from scipy.special import expit as logit # is more stable in case of overflows\n",
    "data = iris_classify()\n",
    "data.plot2d()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we plot it so that the plot shows alcohol and pH and then add a bias.\n",
    "data.bias = 1\n",
    "data.column_y = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cost Function and Update Rule\n",
    "\n",
    "To estimate $\\theta$ we use the vectorized version of the cost function:\n",
    "\n",
    "$$ J(\\theta) = -\\frac{1}{m} \\left[ y^T \\cdot log \\left( logit( X \\cdot \\theta ) \\right) + (1 - y^T) \\cdot log \\left( 1 - logit( X \\cdot \\theta ) \\right) \\right] $$\n",
    "\n",
    "and update rule:\n",
    "\n",
    "$$ \\theta := \\theta - \\frac{\\alpha}{m} \\cdot X^T \\cdot (\\ logit(X \\cdot \\theta) - y )$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we write a function `fit_model` that uses Batch Gradient Descent to estimate $\\theta$ by repeatedly applying the update rule for some number of iterations. We start by defining the hypothesis $h(X, \\theta)$. Remember that the result of the logit can be interpreted as the likelihood that $y=1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def J(X, y, ùúÉ):\n",
    "    return - 1 / len(X) * (y.T @ np.log(logit(X @ ùúÉ)) + (1 - y.T) @ np.log(1- logit(X @ ùúÉ)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def h(X, ùúÉ):\n",
    "    return logit(X @ ùúÉ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Updates parameters theta for #iterations using the logistic regression update rule\n",
    "X: n x m matrix containing the input for n training examples, each having m features\n",
    "y: n x 1 matrix containing the correct class {0,1} for the n training examples\n",
    "alpha: learning rate\n",
    "iterations: number of iterations\n",
    "returns: theta\n",
    "\"\"\"\n",
    "def fit_model(X, y, alpha=0.03, iterations=50000):\n",
    "    m = X.shape[1]            # the number of features\n",
    "    ùúÉ = np.zeros((m, 1))      # vector theta with a weight for every feature\n",
    "    for iter in range(iterations):\n",
    "        ùúÉ -= (alpha / m) * X.T @ ( h(X, ùúÉ) - y )\n",
    "        if (iter + 1) % 10000 == 0:\n",
    "            print(J(X, y, ùúÉ))\n",
    "    return ùúÉ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpreting the coefficients\n",
    "\n",
    "Now, we'll fit the model and look at the values for $\\theta$. Our analysis of the logistic function told us that values of $\\theta^T \\cdot x > 0$ contribute to predicting class 1 and values of $\\theta^T \\cdot x < 0$ contribute to predicting class 1. Therefore, we can see from the sign of $\\theta_1$ that a higher alcohol percentage is associated with good wine and from the sign of $\\theta_2$ that a higher pH-value is associated with bad wine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1. , 4.9, 1.8],\n",
       "       [1. , 4. , 1. ],\n",
       "       [1. , 4.6, 1.3],\n",
       "       [1. , 4.6, 1.5],\n",
       "       [1. , 5.8, 1.6],\n",
       "       [1. , 5.6, 2.4],\n",
       "       [1. , 4.1, 1. ],\n",
       "       [1. , 5.3, 2.3],\n",
       "       [1. , 4.3, 1.3],\n",
       "       [1. , 6. , 2.5],\n",
       "       [1. , 3.8, 1.1],\n",
       "       [1. , 4.5, 1.3],\n",
       "       [1. , 4.7, 1.4],\n",
       "       [1. , 3.7, 1. ],\n",
       "       [1. , 4.8, 1.8],\n",
       "       [1. , 4.2, 1.5],\n",
       "       [1. , 5.8, 1.8],\n",
       "       [1. , 6.1, 2.3],\n",
       "       [1. , 3.9, 1.2],\n",
       "       [1. , 4.4, 1.2],\n",
       "       [1. , 4.5, 1.5],\n",
       "       [1. , 5. , 1.7],\n",
       "       [1. , 4.5, 1.6],\n",
       "       [1. , 4.7, 1.5],\n",
       "       [1. , 5.1, 1.9],\n",
       "       [1. , 5.6, 2.4],\n",
       "       [1. , 5.6, 2.1],\n",
       "       [1. , 4.8, 1.8],\n",
       "       [1. , 6.9, 2.3],\n",
       "       [1. , 4.2, 1.3],\n",
       "       [1. , 5.6, 1.8],\n",
       "       [1. , 5.7, 2.3],\n",
       "       [1. , 6.1, 1.9],\n",
       "       [1. , 5.3, 1.9],\n",
       "       [1. , 4.5, 1.5],\n",
       "       [1. , 5.1, 2.3],\n",
       "       [1. , 6.3, 1.8],\n",
       "       [1. , 5.2, 2.3],\n",
       "       [1. , 5.8, 2.2],\n",
       "       [1. , 6.6, 2.1],\n",
       "       [1. , 4.5, 1.5],\n",
       "       [1. , 5.9, 2.1],\n",
       "       [1. , 5.6, 1.4],\n",
       "       [1. , 5.4, 2.1],\n",
       "       [1. , 4.1, 1.3],\n",
       "       [1. , 5.5, 1.8],\n",
       "       [1. , 4.4, 1.3],\n",
       "       [1. , 3. , 1.1],\n",
       "       [1. , 5.1, 1.6],\n",
       "       [1. , 3.3, 1. ],\n",
       "       [1. , 3.3, 1. ],\n",
       "       [1. , 5.5, 2.1],\n",
       "       [1. , 5.1, 1.8],\n",
       "       [1. , 3.5, 1. ],\n",
       "       [1. , 5. , 1.5],\n",
       "       [1. , 5.1, 1.9],\n",
       "       [1. , 4.5, 1.5],\n",
       "       [1. , 5.1, 2. ],\n",
       "       [1. , 5. , 2. ],\n",
       "       [1. , 4.9, 1.5],\n",
       "       [1. , 5.5, 1.8],\n",
       "       [1. , 4.9, 1.5],\n",
       "       [1. , 6.4, 2. ],\n",
       "       [1. , 4.8, 1.4],\n",
       "       [1. , 3.6, 1.3],\n",
       "       [1. , 4. , 1.3],\n",
       "       [1. , 4.2, 1.3],\n",
       "       [1. , 4.8, 1.8],\n",
       "       [1. , 4.1, 1.3],\n",
       "       [1. , 5.7, 2.5],\n",
       "       [1. , 3.5, 1. ],\n",
       "       [1. , 4.6, 1.4],\n",
       "       [1. , 5.7, 2.1],\n",
       "       [1. , 3.9, 1.1],\n",
       "       [1. , 4. , 1.3],\n",
       "       [1. , 4.7, 1.4],\n",
       "       [1. , 6.7, 2. ],\n",
       "       [1. , 4.5, 1.7],\n",
       "       [1. , 4. , 1.3],\n",
       "       [1. , 4.3, 1.3]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.11471367]]\n",
      "[[0.11159872]]\n",
      "[[0.11096695]]\n",
      "[[0.11079616]]\n",
      "[[0.11074428]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-40.72286222],\n",
       "       [  4.82568771],\n",
       "       [ 10.32101393]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ùúÉ = fit_model(data.train_X, data.train_y)\n",
    "ùúÉ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction function\n",
    "\n",
    "To use the trained model, we need a `predict` function that classifies a set of cases `X`. Since the outcome of the logistic function can be interpreted as the likelihood that $P(y = 1| x; \\theta)$, we choose to return `True` if our model returns an estimation greater or equal than `0.5` and thus indicates $y=1$, or `False` otherwise indicating $y=0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "X: n x m matrix containing the input for n training examples, each having m features\n",
    "theta: m x 1 matrix containing the coefficients for the model\n",
    "Returns true if the hypothesis for a given x >= 0.5 otherwise false\n",
    "\"\"\"\n",
    "def predict(X, ùúÉ):\n",
    "    return h(X, ùúÉ) >= 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then evaluate our model by comparing the predictions on a set of test cases for which we verify if the prediction equals the True label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "X: n x m matrix containing the input for n training examples, each having m features\n",
    "y: n x 1 matrix containing the correct class {0,1} for the n training examples\n",
    "theta: m x 1 matrix containing the coefficients for the model\n",
    "Returns percentage correctly predicted cases in X\n",
    "\"\"\"\n",
    "def evaluate(ùúÉ, X, y):\n",
    "    return sum( predict(X, ùúÉ) == y ) / len(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model has an accuracy of 94%, in other words, the percentage of flowers for which correctly predicts whether it is class 0 or 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9375])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ùúÉ, data.train_X, data.train_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
