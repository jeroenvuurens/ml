{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using libraries\n",
    "\n",
    "So now we've seen how linear regression works analytically. Although it does not seem to be too hard to program a regression algorithm, there can be a lot of complications. Things work differently when for instance the data set is \\*big\\*, there are many features or when we cannot use a least squares cost function. In these cases we can use Gradient Descent. However, if we code gradient decsent from scratch, we have to be very careful not to make mistakes and it sometimes converges very slowly.\n",
    "\n",
    "Alternatively, we can use an existing implementation. For Python, may popular algorithms have already been written an added to an open source library. These algorithms are often rigorously  tested, well documented and very efficient (in fact, most algorithms were implemented in a fast language like Fortran or C++ and made accessible from Python). Choosing an existing implementation makes coding \\*a lot\\* easier and you are far less likely to make mistakes. Here we will use **SKLearn** (pronounce Sci-Kit Learn), but there are many more interesting libraries.\n",
    "\n",
    "So why is Python most popular for scripting Data Science experiments and not one of these fast languages? This is probably partly because Python is comprehensive, compact, highly readable, interactive and very easy to learn and use. Although Python itself is far less efficient, when used with these libraries to do the heavy lifting we will not notice much drop in performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "When loading and preparing the data for use with a library, it is important to read in what format we should provide it. Luckily, for Python, Numpy array's are like the standard format everyone uses, because it's speed, stability and versatilty is unrivaled. However, for some choices, like should we provide the data in row-vectors or column-vectors, should we add a bias or does the library handle that, you should check out an example to see how that works.\n",
    "\n",
    "In our case, SKlearn automatically adds a bias, so we should not add a bias ourselves. The data loaders in ML will only add a bias if we add bias=True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "from ml import *\n",
    "data = advertising_sales_tv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center"
   },
   "source": [
    "# Model\n",
    "\n",
    "The **SKLearn** library contains excellent implementations for many Machine Learning algorithms. To use these libraries it is crucial that you read the documentation or some tutorial on how to use these properly. To use Gradient Descent to estimate a linear regression function, we should use the `partial_fit()` method on the `SGDRegressor`. We can configure the `loss` function to `squared_loss` and `eta0` is the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 93.9],\n",
       "       [ 75.1],\n",
       "       [  4.1],\n",
       "       [195.4],\n",
       "       [261.3],\n",
       "       [276.9],\n",
       "       [141.3],\n",
       "       [  0.7],\n",
       "       [228.3],\n",
       "       [171.3],\n",
       "       [112.9],\n",
       "       [187.9],\n",
       "       [109.8],\n",
       "       [  8.4],\n",
       "       [255.4],\n",
       "       [  7.8],\n",
       "       [281.4],\n",
       "       [292.9],\n",
       "       [276.7],\n",
       "       [188.4],\n",
       "       [120.5],\n",
       "       [129.4],\n",
       "       [109.8],\n",
       "       [  5.4],\n",
       "       [293.6],\n",
       "       [219.8],\n",
       "       [ 17.2],\n",
       "       [ 97.5],\n",
       "       [240.1],\n",
       "       [213.4],\n",
       "       [  8.7],\n",
       "       [ 78.2],\n",
       "       [280.2],\n",
       "       [218.5],\n",
       "       [ 18.8],\n",
       "       [215.4],\n",
       "       [164.5],\n",
       "       [ 62.3],\n",
       "       [ 96.2],\n",
       "       [217.7],\n",
       "       [  8.6],\n",
       "       [182.6],\n",
       "       [240.1],\n",
       "       [137.9],\n",
       "       [125.7],\n",
       "       [163.5],\n",
       "       [206.9],\n",
       "       [136.2],\n",
       "       [234.5],\n",
       "       [ 13.2],\n",
       "       [156.6],\n",
       "       [191.1],\n",
       "       [172.5],\n",
       "       [110.7],\n",
       "       [ 36.9],\n",
       "       [102.7],\n",
       "       [ 73.4],\n",
       "       [166.8],\n",
       "       [ 48.3],\n",
       "       [175.1],\n",
       "       [290.7],\n",
       "       [ 69. ],\n",
       "       [199.8],\n",
       "       [ 87.2],\n",
       "       [289.7],\n",
       "       [ 67.8],\n",
       "       [147.3],\n",
       "       [ 13.1],\n",
       "       [ 25.1],\n",
       "       [237.4],\n",
       "       [ 27.5],\n",
       "       [193.7],\n",
       "       [175.7],\n",
       "       [ 66.1],\n",
       "       [213.5],\n",
       "       [214.7],\n",
       "       [198.9],\n",
       "       [ 88.3],\n",
       "       [248.4],\n",
       "       [241.7],\n",
       "       [ 25.6],\n",
       "       [199.8],\n",
       "       [273.7],\n",
       "       [ 97.2],\n",
       "       [ 70.6],\n",
       "       [228. ],\n",
       "       [205. ],\n",
       "       [  7.3],\n",
       "       [139.5],\n",
       "       [149.7],\n",
       "       [ 28.6],\n",
       "       [210.7],\n",
       "       [222.4],\n",
       "       [266.9],\n",
       "       [170.2],\n",
       "       [216.4],\n",
       "       [ 75.5],\n",
       "       [227.2],\n",
       "       [197.6],\n",
       "       [ 16.9],\n",
       "       [121. ],\n",
       "       [ 76.4],\n",
       "       [135.2],\n",
       "       [229.5],\n",
       "       [187.8],\n",
       "       [ 76.4],\n",
       "       [193.2],\n",
       "       [ 44.5],\n",
       "       [209.6],\n",
       "       [117.2],\n",
       "       [139.2],\n",
       "       [ 69.2],\n",
       "       [ 38.2],\n",
       "       [262.7],\n",
       "       [286. ],\n",
       "       [248.8],\n",
       "       [ 80.2],\n",
       "       [ 18.7],\n",
       "       [ 66.9],\n",
       "       [107.4],\n",
       "       [218.4],\n",
       "       [ 74.7],\n",
       "       [116. ],\n",
       "       [123.1],\n",
       "       [265.6],\n",
       "       [120.2],\n",
       "       [239.3],\n",
       "       [283.6],\n",
       "       [232.1],\n",
       "       [149.8],\n",
       "       [184.9],\n",
       "       [225.8],\n",
       "       [238.2],\n",
       "       [216.8],\n",
       "       [134.3],\n",
       "       [ 59.6],\n",
       "       [ 53.5],\n",
       "       [ 17.2],\n",
       "       [ 31.5],\n",
       "       [280.7],\n",
       "       [239.8],\n",
       "       [142.9],\n",
       "       [220.5],\n",
       "       [206.8],\n",
       "       [250.9],\n",
       "       [ 19.6],\n",
       "       [ 38. ],\n",
       "       [ 17.9],\n",
       "       [ 19.4],\n",
       "       [ 44.7],\n",
       "       [ 43. ],\n",
       "       [284.3],\n",
       "       [ 90.4],\n",
       "       [243.2],\n",
       "       [237.4],\n",
       "       [230.1],\n",
       "       [253.8],\n",
       "       [265.2],\n",
       "       [197.6],\n",
       "       [ 25. ]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SGDRegressor(loss='squared_loss', eta0=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the solution does not converge to value close to the analytical solution but not exactly the same. Also that the SGDRegressor converges more quickly than our own implementation. This is because the SKLearn implementation has a lot of built in extra functionality to speed up training and prevent overfitting. In practice, these solutions may generalize better to unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.10269291] [0.00954835]\n",
      "[0.06011554] [5.47417704]\n",
      "[0.05478194] [6.43329338]\n",
      "[0.05490904] [6.74178412]\n",
      "[0.05477529] [6.85684681]\n",
      "[0.05476347] [6.9038953]\n",
      "[0.05576471] [6.92446553]\n",
      "[0.05927584] [6.93431959]\n",
      "[0.05598238] [6.93833489]\n",
      "[0.05378712] [6.94025056]\n"
     ]
    }
   ],
   "source": [
    "for _ in range(100000):\n",
    "    model.partial_fit(data.train_X, data.train_y )\n",
    "    if _ % 10000 == 0:\n",
    "        print(model.coef_, model.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the SKlearn library we observe that:\n",
    "- it takes less epochs (passes over the dataset) to converge\n",
    "- the model does not neatly converge, we see that $\\theta_0$ oscilates while $\\theta1$ converges. We will see fixes for that.\n",
    "- around $\\theta_1 \\approx 6.94$ we see that it does not truly converge"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
