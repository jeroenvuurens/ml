{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating a Classifier\n",
    "\n",
    "For Classifiers, the squared error is less suitable metric to mearure a model's effectiveness, considering that we work with nominal variables (e.g. good/bad wine). For these tasks, we often use **Recall** and **Precision**. For these, we assume that there is one class that we are actually more interested in. Let's say that our objective is to identify good wines:\n",
    "\n",
    "- Recall: The fraction of good wines that are estimated to be good wines\n",
    "- Precision: The fraction good wines amongst the wines that were estimated to be good wines\n",
    "\n",
    "We have written out an example in a 'confusion matrix' below. In this example, there are 1000 bottles of wine in the data set. Of those only 100 bottles of wine are truly good. On the other hand, our classifier estimates that 120 bottles are good, but of those 120 only 80 are actually good. In this case, recall = TP / (TP + FN) = 80 / 100 = 0.8 and precision = TP / (TP + FP) = 80 / 120 = 0.67.\n",
    "\n",
    "| Estimated/True      | Truly Good Wine         | Truly Bad Wine          | Total |\n",
    "|---------------------|------------------------:|------------------------:|------:|\n",
    "| Estimated Good Wine | True Positives (TP)  80 | False positives (FP) 40 |   120 |\n",
    "| Estimated Bad Wine  | False Negatives (FN) 20 | True Nagatives (TN) 860 |   880 |\n",
    "| Total               |                     100 |                     900 |  1000 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "We will start by loading the Iris data set for Linear Regression, i.e. using the flower type as the target variable and Petal length and width as features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml import iris_pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the Iris dataset. In the dataset there are originally 3 classes, we will just use class 1 and 2 and rename them to 0 and 1 to apply binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = iris_pd()\n",
    "df = df[df.target > 0]\n",
    "df.target -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns='target')\n",
    "y = df.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_X, valid_X, train_y, valid_y = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computing Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(train_X, train_y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute recall we can compute the number of correctly classified items and the number of True Positives. Our classifier recognized 97% of flowers type 1 correctly in the training set and all in the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9714285714285714"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(train_X)\n",
    "type_1 = sum(train_y)\n",
    "true_positives = sum(train_y * y_pred)\n",
    "recall = true_positives / type_1\n",
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(valid_X)\n",
    "type_1 = sum(valid_y)\n",
    "true_positives = sum(valid_y * y_pred)\n",
    "recall = true_positives / type_1\n",
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
